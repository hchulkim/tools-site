{
  "hash": "c3eea59afbb589580938c67acc49c3e7",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"BLP Demystified: From Basics to Brain-Busting Models!\"\nauthor: \"Hyoungchul Kim\"\nengine: julia\nexecute: \n  freeze: auto\nformat: \n  html:\n    toc: false\n    number-sections: true\n    code-overflow: wrap\nbibliography: references.bib\n---\n\n\n\n\nInstall necessary julia packages for later computation:\n\n\n\n::: {#2 .cell execution_count=1}\n``` {.julia .cell-code}\n# You might need these commented codes to install packages\n# using Pkg\n# Pkg.add([\"DataFrames\", \"CSV\", \"GLM\", \"Statistics\", \"LinearAlgebra\", \"Distributions\", \"NLopt\", \"FixedEffectModels\", \"RegressionTables\"])\n```\n:::\n\n\n\n\n\n\n# BLP\n\nThis exercise estimates the demand-side BLP model.\n\n## Motivation\n\nWhy do this? Demand estimation is very important in IO literature because measuring market power is important in IO. How do we quantify market power? Usually we use markup as the measure. But it is hard to directly calculate markup because it depends on the cost function of the firm which is not observed. But IO theory shows that we can actually get the markup using demand elasticity. Thus estimating demand is important. \n\n## Basic: McFadden (1973) style logit model\n\n### Model setup\n\nWe will first estimate a basic logit model with no unobserved demand shifters and no random coefficents. But let's just talk bit about the background of this discrete choice model. Note that most of it is from @train. \n\nEven before @mcfadden74, there has been a long history of the development of the logit model. But @mcfadden74 provides a complete, well-defined econometric model that is consistent with the utility maximization behavior of individuals.\n\n\nIndividual's ($i$) utility maximizing behavior (indirect utility) can be specified as follows:\n\n$$\nu_{ij} = \\underbrace{x_j \\beta + \\alpha p_j}_{\\delta_j} + \\varepsilon_{ij}\n$$\n\nwhere mean utility of outside option is normalized to zero. Also, idiosyncratic shock (i.i.d) follows Type 1 Extreme Value distribution (T1EV). We also assume there are $0, \\ldots, J$ products (denote $0$ as the outside option) where one option is outside option. We can think of $\\delta_j$ as the mean utility from the product $j$. This is because in this parameterization, $\\delta_j$ does not depend on $i$.\n\nNow let's do some math to derive the logit choice probabilities. One benefit about logit model is that we can get a close-form solution. We are going to compute the probability of individuals choosing product $j$ given $p_j$, and $x_j$.\n\n\\begin{align}\n  P (u_{ij} \\geq \\forall_{j' \\neq j} u_{ij'} \\mid x_j, p_j) &= P (x_j \\beta + \\alpha p_j + \\varepsilon_{ij} \\geq \\forall_{j' \\neq j} x_{j'}\\beta + \\alpha p_{j'} + \\varepsilon_{ij'} \\mid x_j, p_j) \\\\\n  &= P ( \\varepsilon_{ij'} \\leq \\varepsilon_{ij} + \\delta_j - \\delta_{j'} \\, \\forall j' \\neq j).\n\\end{align}\n\nIf we assume that $\\varepsilon_{ij}$ is given, we can think of the last term as the cumulative distribution of the T1EV where $F(\\varepsilon_{ij}) = e^{-e^{- \\varepsilon_{ij}}}$. Since we assumed i.i.d., we can express the last term as the product of the individual cumulative distributions (For brevity, we will now denote the conditional logit choice probability as $P_{ij}$):\n\n$$\n  P_{ij} \\mid \\varepsilon_{ij} = \\prod_{j' \\neq j} e^{ - e^{-(\\varepsilon_{ij} + \\delta_j - \\delta_{j'})}}.\n$$\n\nSince $\\varepsilon_{ij}$ is not given, we need o integrate it over density of $\\varepsilon_{ij}$:\n\n$$\n  P_{ij} = \\int \\left(\\prod_{j' \\neq j} e^{ - e^{-(\\varepsilon_{ij} + \\delta_j - \\delta_{j'})}} \\right) e^{- \\varepsilon_{ij}} e^{-e^{\\varepsilon_{ij}}} d \\varepsilon_{ij}.\n$$\n\nNow let's get this into a closed-form expression:\n\nAs a result, we can get the closed-form expression:\n\n$$\n  P_{ij} = \\frac{e^{\\delta_{ij}}}{\\sum_{j'} e^{\\delta_{ij'}}}\n$$\n\nThis could be understood as the *predicted share* function given the fixed values of the parameters.\n\nNote that this is a very simple model because we are not assuming any unobserved product demand shifters that could be affected the utility gained from the product. In fact, we are assuming that econometricians can fully observe all the necessary variables that constructs the mean utility. Thus there is not much econometrics involved. You can just get the parameters as follows:\n\n1. Assuming you have the data on market share, you can use it to match it to $P_{ij} \\cdot M$ where $M$is the total market size.\n\n2. Then since we will get $J$ equations using $J$ market share, we can do simple algebra to get the mean utility $\\delta_j$.\n\n3. Then you can do some nonlinear least squares that minimize the sum of the differences between oberved and predicted shares of all products. This will get you the parameters that best fit the data.\n\n### Adding unobserved demand shifters\n\nWe can add the additional unobserved variables $\\xi_j$ which can be thought of as some demand shifter for product $j$. This allows the model to be more flexible to incorporate the realistic situation where econometrician might not be able to observe some components that might be affecting the utility of getting some product. Thus most of what we did above does not change much. The only problem would be understanding the nature of this unobserved terms with other main parameters of interest. If there is endogeneity, we would need some IV to estimate the parameter. In this section, we will do both cases (OLS, IV).\n\n### Computation (Following @berry1994)\n\nSo how can we retrieve the parameters of interest? Naive way to think about it would be doing some **nonlinear least squares** where you minimize the sum of differences between predicted share and observed shares of all products. The problem is that this directy way is implausible: You would need to know the $\\xi_j$. Since this is unobservable, it is problematic.\n\n**This is where @berry1994 comes in.** He introduces this clever two steps estimation process.\n\n**Step 1: Inversion**\n\nNotation: Let $\\hat{s}_j (\\delta)$ be predicted shares and let $s_j$ be observed shares.[^1]\n\nThen you can use the system of equations from matching actual to predicted shares and invert them to get the mean utility. For this simple case, we can get the following equations:\n\n$$\n  \\delta_j = \\log s_j - \\log \\hat{s}_0, \\quad j = 1, \\ldots, J.\n$$\n\nSo this inversion gets us the value of the mean utility. Then we have the second step.\n\n**Step 2: IV estimation**\n\nBy definition, we have $\\delta_j = x_j \\beta + \\alpha p_j + \\xi_j$. So we can do the regression to retrieve the parameters. I put IV, but this could be just OLS if you can assume the unobserved term is uncorrelated with the price.\n\n[^1]: You might have already noticed, but I kind of use variables without subscript as the vector of the variables. For example, $\\delta$ is just $(\\delta_1, \\ldots, \\delta_J).$\n\n### Coding (with `Julia`)\n\nFinally we will do some coding to get the result we just talked about.\n\n\n\n\n::: {#4 .cell execution_count=1}\n``` {.julia .cell-code}\nusing FixedEffectModels, DataFrames, CSV, RegressionTables \n\n# read in the data\notc = CSV.read(\"data/otc.csv\", DataFrame)\n\n# Run regressions\nols1 = reg(otc, @formula(ln_mkt_share_diff ~ price + promotion)) \nols2 = reg(otc, @formula(ln_mkt_share_diff ~ price + promotion + fe(product)))\nols3 = reg(otc, @formula(ln_mkt_share_diff ~ price + promotion + fe(product) + fe(store)))\niv1 = reg(otc, @formula(ln_mkt_share_diff ~ (price ~ cost) + promotion))\niv2 = reg(otc, @formula(ln_mkt_share_diff ~ (price ~ cost) + promotion + fe(product)))\n\nregtable(ols1, ols2, ols3, iv1, iv2, order = [\"price\"], drop = [\"(Intercept)\"], regression_statistics = [FStatIV, Nobs, R2],\n  labels = Dict(\n    \"price\" => \"Price\",\n    \"promotion\" => \"Promotion\",\n    \"ln_mkt_share_diff\" => \"Log Mkt share difference\"\n  ))\n## Some R codes that I followed\n\n# m1 <- lm(ln_mkt_share_diff ~ price + promotion , data = otc)\n# m2 <- lm(ln_mkt_share_diff ~ price + promotion + factor(product), data = otc)\n# m3 <- lm(ln_mkt_share_diff ~ price + promotion + factor(product) + factor(store), data = otc)\n# m4 <- ivreg(ln_mkt_share_diff ~ price + promotion | . - price + cost, data = otc)\n# m5 <- ivreg(ln_mkt_share_diff ~ price + promotion + factor(product) | . - price + cost, data = otc)\n# stargazer(m1, m2, m3, m4, m5, \n#           omit = c(\"product\", \"store\"),\n#           type = \"text\")\n\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n\n-----------------------------------------------------------------------------\n                                        Log Mkt share difference             \n                          ---------------------------------------------------\n                              (1)        (2)       (3)         (4)        (5)\n-----------------------------------------------------------------------------\nPrice                       0.020   -0.189**   -0.145*    0.069***      0.169\n                          (0.014)    (0.059)   (0.059)     (0.015)    (0.115)\nPromotion                   0.121     0.187*   0.201**       0.149   0.308***\n                          (0.093)    (0.074)   (0.073)     (0.093)    (0.082)\n-----------------------------------------------------------------------------\nproduct Fixed Effects                    Yes       Yes                    Yes\nstore Fixed Effects                                Yes                       \n-----------------------------------------------------------------------------\nEstimator                     OLS        OLS       OLS          IV         IV\n-----------------------------------------------------------------------------\nControls                      Yes                              Yes           \n-----------------------------------------------------------------------------\nFirst-stage F statistic                                  8,147.921    394.113\nN                           1,056      1,056     1,056       1,056      1,056\nR2                          0.003      0.440     0.456      -0.008      0.420\n-----------------------------------------------------------------------------\n\n```\n:::\n:::\n\n\n\n\n\n\n### Caveats\n\nBut we don't usually use this basic setup in IO. This is because the model is bit too simple to fully capture the reality. One of the well known problem is the **Independence of irrelevant alternatives (IIA)**. Basically what this means is that we don't get a realistic demand elasticities. If you want to know more about it, google the famouse ***Red bus, blue bus*** story. \n\n### Solutions?\n\nThere are some ways to alleviate this problem. One of them (which we will not discuss), is using nested logit. Basically we are defining certain group of products where IIA holds within the group but may not hold across the group. So for the case of red bus, blue bus, they would be in a same group.\n\nAnother way is to do enhance the random utility model into logit model with random coefficients. In essence, this is sort of introducing preference heterogeneity of consumers into the model. This is done by interacting consumer preferences with product characteristics.\n\n## Advanced: @blp (Random coefficients logit model)\n\nWe again start with the individual utility function. But now something is added (we will now also explicitly denote markets as $t$):\n\n$$\nu_{ijt} = x_{jt} \\beta_i + \\alpha_i p_{jt} + \\varepsilon_{ijt}\n$$\n\nThe difference is that slope coefficients can now vary across individuals $i$.\n\n## References {.unnumbered}\n\n::: {#refs}\n:::\n\n",
    "supporting": [
      "blp_files"
    ],
    "filters": [],
    "includes": {}
  }
}